"""
AI ê¸°ë°˜ ì½˜í…ì¸  íë ˆì´í„° (SBERT ì¤‘ë³µ ë°©ì§€ ê°•í™” ë²„ì „)
"""
import logging
import sqlalchemy
import pandas as pd
import torch
from typing import List, Dict, Any, Tuple
from sentence_transformers import SentenceTransformer, util
from sqlalchemy.engine import Engine

# í˜•ì˜ í”„ë¡œì íŠ¸ ê³µí†µ ì„¤ì • ë¡œë“œ
import config

# ===============================
# ë¡œê¹… ì„¤ì •
# ===============================
logging.basicConfig(
    level=config.LOG_LEVEL,
    format=config.LOG_FORMAT,
    handlers=[
        logging.FileHandler(config.BASE_DIR / "curator.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ğŸ”¥ [ì•ˆì •ì„±] ëª¨ë¸ ë¡œë“œ (ìµœì´ˆ 1íšŒë§Œ ì‹¤í–‰)
logger.info("ğŸ¤– Sentence-BERT ëª¨ë¸ ë¡œë”© ì¤‘ (ì¤‘ë³µ 90% ì»· ì¤€ë¹„)...")
model = SentenceTransformer('all-MiniLM-L6-v2')
logger.info("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")


class TwoTrackCurator:
    """ì´ì›í™” ì „ëµ íë ˆì´í„° (ìœ ì‚¬ë„ ê¸°ë°˜ ì¤‘ë³µ ì œê±°)"""

    def __init__(self, db_engine: Engine):
        self.engine = db_engine
        # configì—ì„œ ì„ê³„ê°’ ê°€ì ¸ì˜´ (ì˜ˆ: 0.7 ì´ë©´ 70% ì´ìƒ ë¹„ìŠ·í•  ë•Œ ì¤‘ë³µ ì²˜ë¦¬)
        self.similarity_threshold = getattr(config, 'SIMILARITY_THRESHOLD', 0.7)
        self.agro_hit_threshold = getattr(config, 'AGRO_HIT_THRESHOLD', 50)
        self.info_depth_threshold = getattr(config, 'INFO_DEPTH_THRESHOLD', 300)

    def fetch_existing_contents(self) -> List[str]:
        """ì´ë¯¸ ì œì‘ ì™„ë£Œëœ ì‡¼ì¸ ë“¤ì˜ ì œëª©+ë³¸ë¬¸ í…ìŠ¤íŠ¸ ê¸ì–´ì˜¤ê¸°"""
        query = """
                SELECT b.title || ' ' || SUBSTR(b.content, 1, 150) as full_text
                FROM AI_BOARD b
                         JOIN shorts_queue sq ON b.bno = sq.bno
                WHERE sq.status = 1 \
                """
        try:
            with self.engine.connect() as conn:
                df = pd.read_sql(sqlalchemy.text(query), conn)
                return df['full_text'].tolist() if not df.empty else []
        except Exception as e:
            logger.error(f"âŒ ê¸°ì¡´ ê¸°ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def is_duplicate(self, new_text: str, existing_texts: List[str]) -> Tuple[bool, float]:
        """SBERT ë¬¸ë§¥ ë¶„ì„ìœ¼ë¡œ 90% ì¤‘ë³µ ì»· (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë¶„ì„)"""
        if not existing_texts:
            return False, 0.0

        try:
            # í…ìŠ¤íŠ¸ ì„ë² ë”© ìˆ˜ì¹˜í™”
            new_embedding = model.encode(new_text, convert_to_tensor=True)
            existing_embeddings = model.encode(existing_texts, convert_to_tensor=True)

            # ìœ ì‚¬ë„ ê³„ì‚°
            cosine_scores = util.cos_sim(new_embedding, existing_embeddings)
            max_score = float(torch.max(cosine_scores).item())

            # ì„¤ì •í•œ ì„ê³„ê°’ë³´ë‹¤ ë†’ìœ¼ë©´ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼
            return (max_score > self.similarity_threshold), max_score
        except Exception as e:
            logger.error(f"âŒ ìœ ì‚¬ë„ ì²´í¬ ì˜¤ë¥˜: {e}")
            return False, 0.0

    def fetch_candidates(self, track_type: str) -> pd.DataFrame:
        """ì–´ê·¸ë¡œí˜•(AGRO) ë˜ëŠ” ì •ë³´í˜•(INFO) í›„ë³´êµ° ì¡°íšŒ"""
        if track_type == "AGRO":
            condition = f"b.hit > {self.agro_hit_threshold}"
            order = "b.hit DESC"
        else:
            condition = f"LENGTH(b.content) > {self.info_depth_threshold}"
            order = "LENGTH(b.content) DESC"

        query = f"""
            SELECT b.bno, b.title, b.content, b.shorts_script, b.hit, b.p_id
            FROM AI_BOARD b
            WHERE {condition}
              AND NOT EXISTS (
                  SELECT 1 FROM shorts_queue sq 
                  WHERE sq.bno = b.bno AND sq.status = 1
              )
            ORDER BY {order}, b.bno DESC
            FETCH FIRST 20 ROWS ONLY
        """
        try:
            with self.engine.connect() as conn:
                return pd.read_sql(sqlalchemy.text(query), conn)
        except Exception as e:
            logger.error(f"âŒ {track_type} í›„ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()

    def curate(self, count: int = 1) -> List[Dict[str, Any]]:
        """ìµœì¢… ì„ ì • ë¡œì§ (ì¤‘ë³µ ì œê±° í¬í•¨)"""
        logger.info("ğŸ¯ íë ˆì´ì…˜ ê°€ë™: ì¤‘ë³µ í•„í„°ë§ ì‹œì‘")

        existing_texts = self.fetch_existing_contents()
        selected = []

        # ì–´ê·¸ë¡œí˜•, ì •ë³´í˜• ìˆœì„œëŒ€ë¡œ í›‘ê¸°
        for track in ["AGRO", "INFO"]:
            candidates = self.fetch_candidates(track)
            for _, row in candidates.iterrows():
                if len(selected) >= count * 2: # ì›í•˜ëŠ” ê°œìˆ˜ ì°¨ë©´ ì¢…ë£Œ
                    break

                full_text = f"{row['title']} {row['content'][:150]}"
                is_dup, score = self.is_duplicate(full_text, existing_texts)

                if not is_dup:
                    selected.append(row.to_dict())
                    existing_texts.append(full_text) # ì´ë²ˆ ì‚¬ì´í´ ì¤‘ë³µ ë°©ì§€ìš© ì¶”ê°€
                    logger.info(f"âœ… ì„ ì • ì™„ë£Œ: {row['title']} (ìœ ì‚¬ë„ {score:.2f})")
                else:
                    logger.warning(f"ğŸš« ì¤‘ë³µ ì»·: {row['title']} (ìœ ì‚¬ë„ {score:.2f})")

        return selected

def filter_and_queue(engine: Engine) -> List[Dict[str, Any]]:
    """í•˜ìœ„ í˜¸í™˜ ë° ë©”ì¸ í˜¸ì¶œìš© í•¨ìˆ˜"""
    curator = TwoTrackCurator(engine)
    return curator.curate(count=1)